{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "FaceMask-Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX4MBSKfo46r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9bb3c5d-0b52-41df-e0b1-f3dac1bb899f"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn6VlQfLo8Jc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba0b9c68-2e17-4a7c-b5c6-251d5d8fdaf3"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "3.3866142530000047\n",
            "GPU (s):\n",
            "0.10773129900000811\n",
            "GPU speedup over CPU: 31x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMYVjmfVoct6"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "from os import getcwd\n",
        "from os import listdir\n",
        "import cv2\n",
        "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils import shuffle\n",
        "import imutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image  as mpimg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvrbEw0opMXp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf8568b-fe83-4b23-f5d0-ed17fac7274d"
      },
      "source": [
        " from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPtjF6b1ocub",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "2562df37-bca7-4357-9dab-d017f22725ec"
      },
      "source": [
        "print(\"The number of images with facemask labelled 'wit_mask':\",len(os.listdir('/content/drive/My Drive/dataset/with_mask')))\n",
        "print(\"The number of images with facemask labelled 'without_mask':\",len(os.listdir('/content/drive/My Drive/dataset/without_mask')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-00aa87b9796b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The number of images with facemask labelled 'wit_mask':\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/dataset/with_mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The number of images with facemask labelled 'without_mask':\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/dataset/without_mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipdXv9gdocu2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd77faf9-5735-4198-a62f-991af5306b78"
      },
      "source": [
        "def data_summary(main_path):\n",
        "    \n",
        "    yes_path = main_path+'with_mask'\n",
        "    no_path = main_path+'without_mask'\n",
        "        \n",
        "    # number of files (images) that are in the the folder named 'with_mask'\n",
        "    no_with_mask = len(listdir(yes_path))\n",
        "    # number of files (images) that are in the the folder named 'without_mask'\n",
        "    no_without_mask = len(listdir(no_path))\n",
        "    # number of all examples\n",
        "    total = (no_with_mask+no_without_mask)\n",
        "    \n",
        "    with_mask_perc = (no_with_mask* 100.0)/ total\n",
        "    without_mask_perc = (no_without_mask* 100.0)/ total\n",
        "    \n",
        "    print(f\"Number of examples: {total}\")\n",
        "    print(f\"Percentage of positive examples: {with_mask_perc}%, number of positive (with_mask) examples: {no_with_mask}\") \n",
        "    print(f\"Percentage of negative examples: {without_mask_perc}%, number of neg (without_mask) examples: {no_without_mask}\") \n",
        "    \n",
        "main_path_of_the_images = '/content/drive/My Drive/dataset/'    \n",
        "data_summary(main_path_of_the_images)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of examples: 3835\n",
            "Percentage of positive examples: 49.960886571056065%, number of positive (with_mask) examples: 1916\n",
            "Percentage of negative examples: 50.039113428943935%, number of neg (without_mask) examples: 1919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9WkOMLzocvK"
      },
      "source": [
        "def spliting_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "    dataset = []\n",
        "    \n",
        "    for image_file in os.listdir(SOURCE):\n",
        "        data = SOURCE + image_file\n",
        "        if(os.path.getsize(data) > 0):\n",
        "            dataset.append(image_file)\n",
        "        else:\n",
        "            print('Skipped ' + file)\n",
        "            print('Invalid file i.e zero size')\n",
        "    \n",
        "    train_set_length = int(len(dataset) * SPLIT_SIZE)\n",
        "    test_set_length = int(len(dataset) - train_set_length)\n",
        "    train_set = dataset[0:train_set_length]\n",
        "    test_set = dataset[-test_set_length:]\n",
        "       \n",
        "    for image_file in train_set:\n",
        "        temp_train_set = SOURCE + image_file\n",
        "        final_train_set = TRAINING + image_file\n",
        "        copyfile(temp_train_set, final_train_set)\n",
        "    \n",
        "    for image_file in test_set:\n",
        "        temp_test_set = SOURCE + image_file\n",
        "        final_test_set = TESTING + image_file\n",
        "        copyfile(temp_test_set, final_test_set)\n",
        "\n",
        "       \n",
        "        \n",
        "with_mask_source_dir = \"/content/drive/My Drive/dataset/with_mask/\"\n",
        "with_mask_training_dir = \"/content/drive/My Drive/facemask_dataset/training/with_mask_train/\"\n",
        "with_mask_testing_dir = \"/content/drive/My Drive/facemask_dataset/testing/with_mask_test/\"\n",
        "without_mask_source_dir = \"/content/drive/My Drive/dataset/without_mask/\"\n",
        "without_mask_training_dir = \"/content/drive/My Drive/facemask_dataset/training/without_mask_train/\"\n",
        "without_mask_testing_dir = \"/content/drive/My Drive/facemask_dataset/testing/without_mask_test/\"\n",
        "split_size = .8\n",
        "spliting_data(with_mask_source_dir, with_mask_training_dir, with_mask_testing_dir, split_size)\n",
        "spliting_data(without_mask_source_dir, without_mask_training_dir, without_mask_testing_dir, split_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if3WumVdocvg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "271df3d6-e85b-4c3b-bdce-0469c76eafd5"
      },
      "source": [
        "print(\"The number of images with facemask in the training set labelled 'with mask':\", len(os.listdir('/content/drive/My Drive/facemask_dataset/training/with_mask_train')))\n",
        "print(\"The number of images with facemask in the test set labelled 'with mask':\", len(os.listdir('/content/drive/My Drive/facemask_dataset/testing/with_mask_test')))\n",
        "print(\"The number of images without facemask in the training set labelled 'without mask':\", len(os.listdir('/content/drive/My Drive/facemask_dataset/training/without_mask_train')))\n",
        "print(\"The number of images without facemask in the test set labelled 'without mask':\", len(os.listdir('/content/drive/My Drive/facemask_dataset/testing/without_mask_test')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of images with facemask in the training set labelled 'with mask': 1531\n",
            "The number of images with facemask in the test set labelled 'with mask': 383\n",
            "The number of images without facemask in the training set labelled 'without mask': 1534\n",
            "The number of images without facemask in the test set labelled 'without mask': 384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpOYobW1ocv3"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(100, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(100, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(100, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(50, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7Dg1PhfocwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c88cdfca-24c3-40f5-ca2f-7bbf21707a16"
      },
      "source": [
        "TRAINING_DIR = \"/content/drive/My Drive/facemask_dataset/training\"\n",
        "#augumenting the data for increasing the accuracy on training the model\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(TRAINING_DIR, \n",
        "                                                    batch_size=10, \n",
        "                                                    target_size=(150, 150))\n",
        "VALIDATION_DIR = \"/content/drive/My Drive/facemask_dataset/testing\"\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, \n",
        "                                                         batch_size=10, \n",
        "                                                         target_size=(150, 150))\n",
        "checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3065 images belonging to 2 classes.\n",
            "Found 767 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVgt808NTuIL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c06a97c-6d4d-4855-a41a-c4dd3e385170"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "folder_path = '/content/drive/My Drive/facemask_dataset/training'\n",
        "extensions = []\n",
        "for fldr in os.listdir(folder_path):\n",
        "    sub_folder_path = os.path.join(folder_path, fldr)\n",
        "    for filee in os.listdir(sub_folder_path):\n",
        "        file_path = os.path.join(sub_folder_path, filee)\n",
        "        print('** Path: {}  **'.format(file_path), end=\"\\r\", flush=True)\n",
        "        im = Image.open(file_path)\n",
        "        rgb_im = im.convert('RGB')\n",
        "        if filee.split('.')[1] not in extensions:\n",
        "            extensions.append(filee.split('.')[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elmyghBMXXfA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c6c3ae1-7c55-4202-e550-fb47618dcee0"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "folder_path = '/content/drive/My Drive/facemask_dataset/testing'\n",
        "extensions = []\n",
        "for fldr in os.listdir(folder_path):\n",
        "    sub_folder_path = os.path.join(folder_path, fldr)\n",
        "    for filee in os.listdir(sub_folder_path):\n",
        "        file_path = os.path.join(sub_folder_path, filee)\n",
        "        print('** Path: {}  **'.format(file_path), end=\"\\r\", flush=True)\n",
        "        im = Image.open(file_path)\n",
        "        rgb_im = im.convert('RGB')\n",
        "        if filee.split('.')[1] not in extensions:\n",
        "            extensions.append(filee.split('.')[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqb5R0Y0ocwX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34e945d2-1fc2-45af-9842-5162902db474"
      },
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              epochs=30,\n",
        "                              validation_data=validation_generator,\n",
        "                              callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            " 94/307 [========>.....................] - ETA: 23s - loss: 0.5279 - acc: 0.7436"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "307/307 [==============================] - ETA: 0s - loss: 0.4147 - acc: 0.8235INFO:tensorflow:Assets written to: model-001.model/assets\n",
            "307/307 [==============================] - 36s 116ms/step - loss: 0.4147 - acc: 0.8235 - val_loss: 0.2564 - val_acc: 0.8866\n",
            "Epoch 2/30\n",
            "307/307 [==============================] - ETA: 0s - loss: 0.3361 - acc: 0.8672INFO:tensorflow:Assets written to: model-002.model/assets\n",
            "307/307 [==============================] - 35s 115ms/step - loss: 0.3361 - acc: 0.8672 - val_loss: 0.2046 - val_acc: 0.9309\n",
            "Epoch 3/30\n",
            "307/307 [==============================] - 35s 114ms/step - loss: 0.3206 - acc: 0.8734 - val_loss: 0.2235 - val_acc: 0.9035\n",
            "Epoch 4/30\n",
            "307/307 [==============================] - 35s 113ms/step - loss: 0.3143 - acc: 0.8728 - val_loss: 0.3251 - val_acc: 0.9009\n",
            "Epoch 5/30\n",
            "307/307 [==============================] - 35s 113ms/step - loss: 0.3240 - acc: 0.8692 - val_loss: 0.2818 - val_acc: 0.9244\n",
            "Epoch 6/30\n",
            "307/307 [==============================] - ETA: 0s - loss: 0.3115 - acc: 0.8754INFO:tensorflow:Assets written to: model-006.model/assets\n",
            "307/307 [==============================] - 35s 116ms/step - loss: 0.3115 - acc: 0.8754 - val_loss: 0.1950 - val_acc: 0.9387\n",
            "Epoch 7/30\n",
            "307/307 [==============================] - ETA: 0s - loss: 0.2935 - acc: 0.8920INFO:tensorflow:Assets written to: model-007.model/assets\n",
            "307/307 [==============================] - 35s 115ms/step - loss: 0.2935 - acc: 0.8920 - val_loss: 0.1864 - val_acc: 0.9452\n",
            "Epoch 8/30\n",
            "307/307 [==============================] - 35s 113ms/step - loss: 0.2794 - acc: 0.8940 - val_loss: 0.2258 - val_acc: 0.8996\n",
            "Epoch 9/30\n",
            "307/307 [==============================] - ETA: 0s - loss: 0.2811 - acc: 0.8891INFO:tensorflow:Assets written to: model-009.model/assets\n",
            "307/307 [==============================] - 35s 115ms/step - loss: 0.2811 - acc: 0.8891 - val_loss: 0.1786 - val_acc: 0.9518\n",
            "Epoch 10/30\n",
            "307/307 [==============================] - ETA: 0s - loss: 0.2720 - acc: 0.8940INFO:tensorflow:Assets written to: model-010.model/assets\n",
            "307/307 [==============================] - 35s 115ms/step - loss: 0.2720 - acc: 0.8940 - val_loss: 0.1517 - val_acc: 0.9505\n",
            "Epoch 11/30\n",
            "307/307 [==============================] - 34s 112ms/step - loss: 0.2674 - acc: 0.8976 - val_loss: 0.1538 - val_acc: 0.9557\n",
            "Epoch 12/30\n",
            "307/307 [==============================] - ETA: 0s - loss: 0.2662 - acc: 0.9011INFO:tensorflow:Assets written to: model-012.model/assets\n",
            "307/307 [==============================] - 35s 115ms/step - loss: 0.2662 - acc: 0.9011 - val_loss: 0.1437 - val_acc: 0.9544\n",
            "Epoch 13/30\n",
            "307/307 [==============================] - ETA: 0s - loss: 0.2788 - acc: 0.8930INFO:tensorflow:Assets written to: model-013.model/assets\n",
            "307/307 [==============================] - 35s 114ms/step - loss: 0.2788 - acc: 0.8930 - val_loss: 0.1242 - val_acc: 0.9596\n",
            "Epoch 14/30\n",
            "307/307 [==============================] - 34s 111ms/step - loss: 0.2512 - acc: 0.9038 - val_loss: 0.1873 - val_acc: 0.9505\n",
            "Epoch 15/30\n",
            "307/307 [==============================] - 34s 111ms/step - loss: 0.2498 - acc: 0.9044 - val_loss: 0.1376 - val_acc: 0.9570\n",
            "Epoch 16/30\n",
            "307/307 [==============================] - 34s 112ms/step - loss: 0.2265 - acc: 0.9168 - val_loss: 0.1860 - val_acc: 0.9452\n",
            "Epoch 17/30\n",
            "307/307 [==============================] - ETA: 0s - loss: 0.2335 - acc: 0.9113INFO:tensorflow:Assets written to: model-017.model/assets\n",
            "307/307 [==============================] - 35s 115ms/step - loss: 0.2335 - acc: 0.9113 - val_loss: 0.1100 - val_acc: 0.9661\n",
            "Epoch 18/30\n",
            "307/307 [==============================] - 34s 111ms/step - loss: 0.2283 - acc: 0.9188 - val_loss: 0.1177 - val_acc: 0.9635\n",
            "Epoch 19/30\n",
            "307/307 [==============================] - 34s 111ms/step - loss: 0.2015 - acc: 0.9220 - val_loss: 0.1367 - val_acc: 0.9518\n",
            "Epoch 20/30\n",
            "307/307 [==============================] - 34s 111ms/step - loss: 0.2194 - acc: 0.9132 - val_loss: 0.1197 - val_acc: 0.9661\n",
            "Epoch 21/30\n",
            "307/307 [==============================] - 34s 111ms/step - loss: 0.2124 - acc: 0.9155 - val_loss: 0.1930 - val_acc: 0.9140\n",
            "Epoch 22/30\n",
            "307/307 [==============================] - 34s 112ms/step - loss: 0.2041 - acc: 0.9158 - val_loss: 0.1524 - val_acc: 0.9570\n",
            "Epoch 23/30\n",
            "307/307 [==============================] - ETA: 0s - loss: 0.1954 - acc: 0.9312INFO:tensorflow:Assets written to: model-023.model/assets\n",
            "307/307 [==============================] - 35s 114ms/step - loss: 0.1954 - acc: 0.9312 - val_loss: 0.1063 - val_acc: 0.9687\n",
            "Epoch 24/30\n",
            "307/307 [==============================] - 34s 111ms/step - loss: 0.2037 - acc: 0.9197 - val_loss: 0.1366 - val_acc: 0.9583\n",
            "Epoch 25/30\n",
            "307/307 [==============================] - 34s 112ms/step - loss: 0.2134 - acc: 0.9197 - val_loss: 0.1096 - val_acc: 0.9674\n",
            "Epoch 26/30\n",
            "307/307 [==============================] - 35s 113ms/step - loss: 0.1789 - acc: 0.9276 - val_loss: 0.1363 - val_acc: 0.9648\n",
            "Epoch 27/30\n",
            "307/307 [==============================] - 34s 112ms/step - loss: 0.1995 - acc: 0.9266 - val_loss: 0.1145 - val_acc: 0.9609\n",
            "Epoch 28/30\n",
            "307/307 [==============================] - 34s 111ms/step - loss: 0.1833 - acc: 0.9295 - val_loss: 0.1419 - val_acc: 0.9583\n",
            "Epoch 29/30\n",
            "307/307 [==============================] - 34s 110ms/step - loss: 0.1825 - acc: 0.9289 - val_loss: 0.1260 - val_acc: 0.9544\n",
            "Epoch 30/30\n",
            "307/307 [==============================] - 34s 111ms/step - loss: 0.1779 - acc: 0.9321 - val_loss: 0.1722 - val_acc: 0.9452\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_9elSkEy4cg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "1cf9b560-3d05-4b9b-f6ad-15d45f27ce51"
      },
      "source": [
        "from matplotlib import pyplot as plt \n",
        "\n",
        "plt.plot(history.history['acc'] , label='tranning accuracy')\n",
        "plt.plot(history.history['val_acc'] , label = 'validation accuracy')\n",
        "plt.plot(history.history['loss'] , label='tranning loss')\n",
        "plt.plot(history.history['val_loss'] , label = 'validation loss')\n",
        "plt.xlabel(\"# epochs\")\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6wtVDTAocwj"
      },
      "source": [
        "face_clsfr=cv2.CascadeClassifier('/content/drive/My Drive/haarcascade_frontalface_default.xml')\n",
        "labels_dict={0:'without_mask',1:'with_mask'}\n",
        "color_dict={0:(0,0,255),1:(0,255,0)}\n",
        "\n",
        "size = 4\n",
        "webcam = cv2.VideoCapture(0) #Use camera 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d657NgKozpT0"
      },
      "source": [
        "#\n",
        "# based on: https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=2viqYx97hPMi\n",
        "#\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import numpy as np\n",
        "\n",
        "def init_camera():\n",
        "  \"\"\"Create objects and functions in HTML/JavaScript to access local web camera\"\"\"\n",
        "\n",
        "  js = Javascript('''\n",
        "\n",
        "    // global variables to use in both functions\n",
        "    var div = null;\n",
        "    var video = null;   // <video> to display stream from local webcam\n",
        "    var stream = null;  // stream from local webcam\n",
        "    var canvas = null;  // <canvas> for single frame from <video> and convert frame to JPG\n",
        "    var img = null;     // <img> to display JPG after processing with `cv2`\n",
        "\n",
        "    async function initCamera() {\n",
        "      // place for video (and eventually buttons)\n",
        "      div = document.createElement('div');\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      // <video> to display video\n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      div.appendChild(video);\n",
        "\n",
        "      // get webcam stream and assing to <video>\n",
        "      stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "      video.srcObject = stream;\n",
        "\n",
        "      // start playing stream from webcam in <video>\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // <canvas> for frame from <video>\n",
        "      canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      //div.appendChild(input_canvas); // there is no need to display to get image (but you can display it for test)\n",
        "\n",
        "      // <img> for image after processing with `cv2`\n",
        "      img = document.createElement('img');\n",
        "      img.width = video.videoWidth;\n",
        "      img.height = video.videoHeight;\n",
        "      div.appendChild(img);\n",
        "    }\n",
        "\n",
        "    async function takeImage(quality) {\n",
        "      // draw frame from <video> on <canvas>\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "      // stop webcam stream\n",
        "      //stream.getVideoTracks()[0].stop();\n",
        "\n",
        "      // get data from <canvas> as JPG image decoded base64 and with header \"data:image/jpg;base64,\"\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "      //return canvas.toDataURL('image/png', quality);\n",
        "    }\n",
        "\n",
        "    async function showImage(image) {\n",
        "      // it needs string \"data:image/jpg;base64,JPG-DATA-ENCODED-BASE64\"\n",
        "      // it will replace previous image in `<img src=\"\">`\n",
        "      img.src = image;\n",
        "      // TODO: create <img> if doesn't exists, \n",
        "      // TODO: use `id` to use different `<img>` for different image - like `name` in `cv2.imshow(name, image)`\n",
        "    }\n",
        "\n",
        "  ''')\n",
        "\n",
        "  display(js)\n",
        "  eval_js('initCamera()')\n",
        "\n",
        "def take_frame(quality=0.8):\n",
        "  \"\"\"Get frame from web camera\"\"\"\n",
        "\n",
        "  data = eval_js('takeImage({})'.format(quality))  # run JavaScript code to get image (JPG as string base64) from <canvas>\n",
        "\n",
        "  header, data = data.split(',')  # split header (\"data:image/jpg;base64,\") and base64 data (JPG)\n",
        "  data = b64decode(data)  # decode base64\n",
        "  data = np.frombuffer(data, dtype=np.uint8)  # create numpy array with JPG data\n",
        "\n",
        "  img = cv2.imdecode(data, cv2.IMREAD_UNCHANGED)  # uncompress JPG data to array of pixels\n",
        "\n",
        "  return img\n",
        "\n",
        "def show_frame(img, quality=0.8):\n",
        "  \"\"\"Put frame as <img src=\"data:image/jpg;base64,....\"> \"\"\"\n",
        "\n",
        "  ret, data = cv2.imencode('.jpg', img)  # compress array of pixels to JPG data\n",
        "\n",
        "  data = b64encode(data)  # encode base64\n",
        "  data = data.decode()  # convert bytes to string\n",
        "  data = 'data:image/jpg;base64,' + data  # join header (\"data:image/jpg;base64,\") and base64 data (JPG)\n",
        "\n",
        "  eval_js('showImage(\"{}\")'.format(data))  # run JavaScript code to put image (JPG as string base64) in <img>\n",
        "                                           # argument in `showImage` needs `\" \"` "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taNjoJoPztEG"
      },
      "source": [
        "init_camera() #init javascript code\n",
        "classifier = cv2.CascadeClassifier('/content/drive/My Drive/haarcascade_frontalface_default.xml')\n",
        "\n",
        "while(True):\n",
        "\n",
        "  im = take_frame()\n",
        "  mini = cv2.resize(im, (im.shape[1] // size, im.shape[0] // size))\n",
        "  #gray = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  faces = classifier.detectMultiScale(mini) ########\n",
        "  for f in faces:\n",
        "    (x, y, w, h) = [v * size for v in f] #Scale the shapesize backup\n",
        "    face_img = im[y:y+w , x:x+w]###############\n",
        "    resized = cv2.resize(face_img , (150,150)) # resize the face_img\n",
        "    normalized = resized /255.0 # normalized the value to 0 and 1\n",
        "    reshaped = np.reshape(normalized ,(1,150,150,3)) # convert the normalized img array to 4d for cnn\n",
        "    reshaped = np.vstack([reshaped])\n",
        "    result = model.predict(reshaped) #for getting the prediction\n",
        "\n",
        "    # print(result)\n",
        "    label = np.argmax(result , axis =1)[0] #########\n",
        "    # print (label)\n",
        "\n",
        "    cv2.rectangle(im , (x,y) , (x+w , y+h) ,color_dict[label] ,2) \n",
        "    #rectangle x,y one point and x+w ,y+h is another point. 2 is the border thin\n",
        "    cv2.rectangle(im ,(x,y-40),(x+w , y) , color_dict[label] , -1) #-1 for color filled\n",
        "    conf_perc = \"{:.2f}%\".format(result[0][label] * 100)\n",
        "    cv2.putText(im , labels_dict[label]+\" \" +str(conf_perc) , (x,y-10) , cv2.FONT_HERSHEY_COMPLEX , 0.8,(255,255,255) , 2)\n",
        "   \n",
        "    #cv2_imshow(gray)  # it creates new image for every frame (it doesn't replace previous image) so it is useless\n",
        "    #show_frame(gray)  # it replace previous image\n",
        "\n",
        "    show_frame(im) #it replaces the previous images\n",
        "    key = cv2.waitKey(1)\n",
        "\n",
        "    if(key==27):\n",
        "      break\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "source.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK_3-C8wP3cS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "30683415-d28c-43f4-8212-a28f9b859012"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "classifier = cv2.CascadeClassifier('/content/drive/My Drive/haarcascade_frontalface_default.xml')\n",
        "\n",
        "im = cv2.imread(cv2.samples.findFile(\"/content/drive/My Drive/pic2.jpg\"))\n",
        "print(im.shape[0]/size)\n",
        "mini = cv2.resize(im, (im.shape[1] // size, im.shape[0] // size))\n",
        "#gray = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "faces = classifier.detectMultiScale(mini) ########\n",
        "for f in faces:\n",
        "  (x, y, w, h) = [v * size for v in f] #Scale the shapesize backup\n",
        "  face_img = im[y:y+w , x:x+w] ###############\n",
        "  resized = cv2.resize(face_img , (150,150)) # resize the face_img\n",
        "  normalized = resized /255.0 # normalized the value to 0 and 1\n",
        "  reshaped = np.reshape(normalized ,(1,150,150,3)) # convert the normalized img array to 4d for cnn\n",
        "  reshaped = np.vstack([reshaped])\n",
        "  result = model.predict(reshaped) #for getting the prediction\n",
        "\n",
        "  print(result)\n",
        "  label = np.argmax(result , axis =1)[0] #########\n",
        "  print (label)\n",
        "  cv2.rectangle(im , (x,y) , (x+w , y+h) ,color_dict[label] ,2) \n",
        "  #rectangle x,y one point and x+w ,y+h is another point. 2 is the border thin\n",
        "  cv2.rectangle(im ,(x,y-40),(x+w , y) , color_dict[label] , -1) #-1 for color filled\n",
        "  conf_perc = \"{:.2f}%\".format(result[0][label] * 100)\n",
        "  cv2.putText(im , labels_dict[label]+\" \" +str(conf_perc) , (x,y-10) , cv2.FONT_HERSHEY_COMPLEX , 0.8,(255,255,255) , 2)\n",
        "  \n",
        "  #cv2_imshow(gray)  # it creates new image for every frame (it doesn't replace previous image) so it is useless\n",
        "  #show_frame(gray)  # it replace previous image\n",
        "\n",
        "  # show_frame(im) #it replaces the previous images\n",
        "  cv2_imshow(im)\n",
        "  cv2.waitKey(0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-985f2e7c9232>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/haarcascade_frontalface_default.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/pic2.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/core/src/utils/samples.cpp:62: error: (-2:Unspecified error) OpenCV samples: Can't find required data file: /content/drive/My Drive/pic2.jpg in function 'findFile'\n"
          ]
        }
      ]
    }
  ]
}